# Industrial Alarm Logs Data Processing & EDA Overview

## Overview
This project focuses on analyzing alarm logs generated by industrial packaging machines. The goal is to use these logs to develop machine learning models for tasks such as next-alarm forecasting, multi-label classification, sequence prediction, and anomaly detection. The dataset comes originally as a raw CSV file (`alarms.csv`), which is then processed into various formats for direct use in modeling.

## Data Files

### Raw Data
- **alarms.csv**:  
  The original dataset containing raw alarm logs. Each row in the CSV provides:
  - **timestamp**: When the alarm occurred.
  - **alarm**: The alarm code (154 distinct codes).
  - **serial**: Identifier for the machine generating the alarm.

### Processed Data
These files are produced by the data processing pipeline implemented in `dataset.py` and are the outputs of several transformation steps applied to the raw data.

- **all_alarms.pickle**
- **all_alarms.json**
- **all_alarms.npz**

They have undergone the following processing steps:
- **Segmentation and Windowing**:  
  The raw alarm logs are divided into fixed-length input/output sequences based on sliding windows (e.g., an input window of 1720 minutes and an output window of 480 minutes).
- **Pruning and Padding**:  
  Consecutive duplicate alarms are removed (pruning) to reduce noise, and the sequences are padded to ensure all samples have uniform length.
- **Dataset Splitting**:  
  The processed data is split into training and test sets with additional stratification based on machine serial numbers, making the data ready for various machine learning tasks.

## EDA and Data Verification

### Raw Data EDA
Extensive exploratory data analysis (EDA) has been performed on the raw `alarms.csv` file to understand:
- The distribution of alarm codes and the imbalance present in the data.
- Temporal patterns, such as daily or weekly trends in alarm occurrences.
- Machine-specific behavior by analyzing alarms per machine.

### Processed Data EDA
While the processed files are designed to be “ready-to-use” for modeling, it is still advisable to perform some basic checks, such as:
- **Verifying Shapes and Splits**:  
  Confirm that the training and test splits have the expected number of samples and that sequence lengths match the intended design.
- **Distribution Checks**:  
  Validate that the alarm code distributions within the sequences remain consistent with the raw data insights.
- **Sanity Checks**:  
  Ensure that the processing steps (e.g., pruning and padding) have been applied correctly.

**Note:**  
Since the processed files (`all_alarms.json`, `all_alarms.npz`, and `all_alarms.pickle`) are derived directly from the already-analyzed raw data, extensive EDA on these files is optional. Our primary focus for modeling is to work with the raw data directly, knowing that the processing pipeline has been verified to produce data in a format suitable for machine learning tasks.
